<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Comcast S4 Call Simulator</title>
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      background: #f5f7fa;
      color: #333;
      padding: 20px;
      text-align: center;
    }

    h1 {
      font-size: 2em;
      color: #444;
    }

    .container {
      max-width: 800px;
      margin: 0 auto;
      background: #fff;
      border-radius: 12px;
      padding: 20px;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    }

    #transcript, #ai-response, #evaluation {
      border: 1px solid #ddd;
      padding: 15px;
      margin: 15px 0;
      min-height: 60px;
      text-align: left;
      background: #fefefe;
      border-radius: 8px;
      overflow-y: auto;
    }

    button {
      padding: 12px 20px;
      margin: 10px;
      font-size: 16px;
      border: none;
      border-radius: 6px;
      cursor: pointer;
    }

    #start-btn { background-color: #4CAF50; color: white; }
    #send-btn { background-color: #2196F3; color: white; }
    #mic-btn.active { background-color: #ff3333; color: white; }
    #speaker-btn.active { background-color: #ff3333; color: white; }
    #send-btn:disabled, #mic-btn:disabled, #speaker-btn:disabled { background-color: #cccccc; }

    #loader {
      display: none;
      margin: 10px;
      font-style: italic;
    }

    #settings {
      margin: 15px 0;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Comcast S4 Call Simulator üéß</h1>
    <div id="settings">
      <label>
        <input type="checkbox" id="autoSendCheckbox" checked>
        Enable Auto-Send on Silence
      </label><br>
      <label>
        Silence Timeout (seconds):
        <input type="number" id="timeoutSeconds" value="60" min="2" max="120">
      </label>
    </div>
    <button id="start-btn">üé§ Start Listening</button>
    <button id="send-btn" disabled>‚úâÔ∏è Send</button>
    <button id="mic-btn" disabled>Microphone: Off</button>
    <button id="speaker-btn" disabled>Speaker: Off</button>
    <div id="loader">‚è≥ AI is thinking...</div>

    <h3>Agent Said:</h3>
    <div id="transcript">‚Äî</div>

    <h3>Customer (AI) Said:</h3>
    <div id="ai-response">‚Äî</div>

    <h3>S4 Evaluation:</h3>
    <div id="evaluation">‚Äî</div>
  </div>

  <script type="module">
    import { evaluateS4Response } from './s4_guidelines.js';

    const WORKER_URL = 'https://workers-playground-tiny-sky-5f02.amrassal91.workers.dev';

    const startBtn = document.getElementById('start-btn');
    const sendBtn = document.getElementById('send-btn');
    const micBtn = document.getElementById('mic-btn');
    const speakerBtn = document.getElementById('speaker-btn');
    const loader = document.getElementById('loader');
    const transcriptEl = document.getElementById('transcript');
    const aiResponseEl = document.getElementById('ai-response');
    const evaluationEl = document.getElementById('evaluation');
    const autoSendCheckbox = document.getElementById('autoSendCheckbox');
    const timeoutSecondsInput = document.getElementById('timeoutSeconds');

    let recognition, finalTranscript = '', isRecognizing = false;
    let autoSendEnabled = true;
    let autoSendDelay = 60000;
    let autoSendTimer;
    let callStage = 'S1';
    let conversationHistory = [];

    function initRecognition() {
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR) {
        alert('Speech recognition not supported.');
        return null;
      }
      const rec = new SR();
      rec.lang = 'en-US';
      rec.interimResults = true;
      rec.continuous = true;

      rec.onstart = () => {
        isRecognizing = true;
        startBtn.textContent = 'üõë Stop';
        transcriptEl.textContent = 'Listening...';
        micBtn.disabled = false;
        micBtn.classList.add('active');
        micBtn.textContent = 'Microphone: On';
      };

      rec.onresult = e => {
        let interim = '';
        for (let i = e.resultIndex; i < e.results.length; i++) {
          const t = e.results[i][0].transcript;
          if (e.results[i].isFinal) {
            finalTranscript = t;
            if (t.toLowerCase().includes('send')) {
              clearTimeout(autoSendTimer);
              sendMessage(finalTranscript.replace(/send/i, '').trim());
              return;
            }
          } else {
            interim = t;
          }
        }
        transcriptEl.textContent = finalTranscript + interim;
        sendBtn.disabled = !finalTranscript.trim();

        if (autoSendEnabled && finalTranscript.trim()) {
          clearTimeout(autoSendTimer);
          autoSendTimer = setTimeout(() => {
            sendMessage(finalTranscript.trim());
          }, autoSendDelay);
        }
      };

      rec.onerror = e => {
        let errorMessage = '';
        switch (e.error) {
          case 'network':
            errorMessage = 'Network error in speech recognition. Retrying in 3 seconds...';
            break;
          default:
            errorMessage = `Speech error: ${e.error}`;
        }
        transcriptEl.textContent = errorMessage;
        console.error('Speech error:', e.error);
        if (isRecognizing) {
          setTimeout(() => {
            if (isRecognizing) startRec();
          }, 3000);
        }
      };

      rec.onend = () => {
        if (!isRecognizing) {
          startBtn.textContent = 'üé§ Start Listening';
          micBtn.classList.remove('active');
          micBtn.textContent = 'Microphone: Off';
          micBtn.disabled = true;
          sendBtn.disabled = true;
        }
      };

      return rec;
    }

    function startRec() {
      if (!recognition) recognition = initRecognition();
      finalTranscript = '';
      transcriptEl.textContent = '';
      sendBtn.disabled = true;
      try {
        recognition.start();
      } catch (e) {
        transcriptEl.textContent = 'Microphone access denied. Please allow access.';
        stopRec();
      }
    }

    function stopRec() {
      if (recognition && isRecognizing) {
        recognition.stop();
        isRecognizing = false;
        clearTimeout(autoSendTimer);
      }
    }

    async function sendMessage(text) {
      if (!text) return;
      stopRec();
      sendBtn.disabled = true;
      loader.style.display = 'block';
      aiResponseEl.textContent = '';
      evaluationEl.textContent = '';
      speakerBtn.disabled = false;
      speakerBtn.classList.add('active');
      speakerBtn.textContent = 'Speaker: On';

      try {
        // Evaluate agent response
        const evaluation = evaluateS4Response(text, callStage, conversationHistory);
        evaluationEl.innerHTML = evaluation.comment + `<br><b>Score:</b> ${evaluation.score} points`;
        conversationHistory.push({ role: 'agent', content: text });

        // Generate customer response
        const prompt = `
You are a Comcast postpaid small to medium business customer with TV, landline, or Internet service. You have a concern about billing (e.g., overcharge) or technical support (e.g., Internet outage). Respond ONLY as the customer, never as an agent. Use a natural, conversational tone, reflecting emotions like frustration or relief based on the agent‚Äôs response: "${text}". Provide account details (e.g., address, account number) if asked for verification. Acknowledge resolutions or express dissatisfaction if unresolved. Current call stage: ${callStage}. Conversation history: ${JSON.stringify(conversationHistory)}. Start with a greeting if this is the first response (e.g., "Hi, this is Mark Smith from ABC Corp. My bill doubled this month!").`;
        const payload = { contents: [{ parts: [{ text: prompt }] }] };
        const res = await fetch(WORKER_URL, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(payload)
        });

        const data = await res.json();
        const reply = data.candidates?.[0]?.content?.parts?.[0]?.text || '(No response)';
        aiResponseEl.textContent = reply;
        conversationHistory.push({ role: 'customer', content: reply });

        // Update call stage
        if (callStage === 'S1' && text.match(/(fixed|resolved|take care of)/i)) {
          callStage = 'S2';
        } else if (callStage === 'S2' && text.match(/(review your account|best value)/i)) {
          callStage = 'S3';
        } else if (callStage === 'S3' && text.match(/(recap|next steps)/i)) {
          callStage = 'S4';
        }

        speak(reply, () => {
          startRec();
        });
      } catch (e) {
        aiResponseEl.textContent = 'AI Error: ' + e.message;
        console.error('Fetch failed:', e);
        speak('Error: Unable to get AI response.', () => {
          startRec();
        });
      } finally {
        loader.style.display = 'none';
        speakerBtn.classList.remove('active');
        speakerBtn.textContent = 'Speaker: Off';
        speakerBtn.disabled = true;
      }
    }

    function speak(text, callback) {
      if (!window.speechSynthesis) {
        console.log('Speech synthesis not supported.');
        if (callback) callback();
        return;
      }
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'en-US';
      utter.onend = () => {
        console.log('TTS finished');
        if (callback) callback();
      };
      window.speechSynthesis.speak(utter);
    }

    startBtn.addEventListener('click', () => {
      isRecognizing ? stopRec() : startRec();
    });

    sendBtn.addEventListener('click', () => {
      clearTimeout(autoSendTimer);
      sendMessage(finalTranscript.trim());
    });

    autoSendCheckbox.addEventListener('change', (e) => {
      autoSendEnabled = e.target.checked;
      if (!autoSendEnabled) {
        clearTimeout(autoSendTimer);
      }
    });

    timeoutSecondsInput.addEventListener('input', (e) => {
      autoSendDelay = parseInt(e.target.value) * 1000;
    });
  </script>
</body>
</html>
