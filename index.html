<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI Call Simulator</title>
  <style>
    body { font-family: sans-serif; padding: 2em; }
    #messages { border: 1px solid #ccc; padding: 1em; height: 200px; overflow-y: auto; margin-bottom: 1em; }
    #settings { margin-bottom: 1em; }
    .ai { color: blue; }
    .user { color: green; }
  </style>
</head>
<body>
  <h1>ðŸ§  AI Call Simulator</h1>
  
  <div id="settings">
    <label>
      <input type="checkbox" id="autoSendCheckbox" checked>
      Enable Auto-Send on Silence
    </label><br>
    <label>
      Silence Timeout (seconds):
      <input type="number" id="timeoutSeconds" value="5" min="2" max="60">
    </label>
  </div>

  <div id="messages"></div>
  <button id="startBtn">Start Conversation</button>

  <script>
    const startBtn = document.getElementById("startBtn");
    const autoSendCheckbox = document.getElementById("autoSendCheckbox");
    const timeoutSecondsInput = document.getElementById("timeoutSeconds");
    const messagesDiv = document.getElementById("messages");

    let recognition, autoSendTimer, collectedTranscript = "";
    let autoSendEnabled = true;
    let autoSendDelay = 5000;

    function appendMessage(who, text) {
      const msg = document.createElement("div");
      msg.className = who;
      msg.textContent = who.toUpperCase() + ": " + text;
      messagesDiv.appendChild(msg);
      messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }

    function speak(text, callback) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.onend = () => {
        if (callback) callback();
      };
      speechSynthesis.speak(utterance);
    }

    function startRecognition() {
      collectedTranscript = "";
      recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.lang = "en-US";
      recognition.interimResults = false;
      recognition.continuous = false;

      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        appendMessage("user", transcript);

        // Check for manual "send" keyword
        if (transcript.toLowerCase().includes("send")) {
          clearTimeout(autoSendTimer);
          processUserInput(transcript.replace(/send/i, "").trim());
          return;
        }

        collectedTranscript = transcript;

        if (autoSendEnabled) {
          clearTimeout(autoSendTimer);
          autoSendTimer = setTimeout(() => {
            processUserInput(collectedTranscript);
          }, autoSendDelay);
        }
      };

      recognition.onerror = (e) => {
        console.error("Speech error:", e.error);
      };

      recognition.onend = () => {
        console.log("Recognition ended.");
      };

      recognition.start();
    }

    function processUserInput(text) {
      if (!text) return;
      appendMessage("user", text);
      collectedTranscript = "";

      // Simulate AI thinking
      const response = generateFakeAIResponse(text);
      speak(response, () => {
        startRecognition(); // Auto-restart mic after speaking
      });
      appendMessage("ai", response);
    }

    function generateFakeAIResponse(text) {
      // Replace this with real API call
      return "You said: " + text + ". That's interesting!";
    }

    startBtn.addEventListener("click", () => {
      startRecognition();
    });

    autoSendCheckbox.addEventListener("change", (e) => {
      autoSendEnabled = e.target.checked;
    });

    timeoutSecondsInput.addEventListener("input", (e) => {
      autoSendDelay = parseInt(e.target.value) * 1000;
    });
  </script>
</body>
</html>
