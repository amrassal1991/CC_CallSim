<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Comcast S4 Call Simulator</title>
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      background: #f5f7fa;
      color: #333;
      padding: 20px;
      text-align: center;
    }

    h1 {
      font-size: 2em;
      color: #444;
    }

    .container {
      max-width: 800px;
      margin: 0 auto;
      background: #fff;
      border-radius: 12px;
      padding: 20px;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    }

    #transcription {
      border: 1px solid #ddd;
      padding: 15px;
      margin: 15px 0;
      max-height: 400px;
      text-align: left;
      background: #fefefe;
      border-radius: 8px;
      overflow-y: auto;
      font-size: 14px;
    }

    button {
      padding: 12px 20px;
      margin: 10px;
      font-size: 16px;
      border: none;
      border-radius: 6px;
      cursor: pointer;
    }

    #start-btn { background-color: #4CAF50; color: white; }
    #start-btn.active { background-color: #ff3333; color: white; }
    #send-btn { background-color: #2196F3; color: white; }
    #mic-btn.active { background-color: #ff3333; color: white; }
    #speaker-btn.active { background-color: #ff3333; color: white; }
    #send-btn:disabled, #mic-btn:disabled, #speaker-btn:disabled { background-color: #cccccc; }

    #loader {
      display: none;
      margin: 10px;
      font-style: italic;
    }

    #settings {
      margin: 15px 0;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Comcast S4 Call Simulator ğŸ§</h1>
    <div id="settings">
      <label>
        <input type="checkbox" id="autoSendCheckbox" checked>
        Enable Auto-Send on Silence
      </label><br>
      <label>
        Silence Timeout (seconds):
        <input type="number" id="timeoutSeconds" value="60" min="2" max="120">
      </label>
    </div>
    <button id="start-btn">ğŸ¤ Start Conversation</button>
    <button id="send-btn" disabled>âœ‰ï¸ Send</button>
    <button id="mic-btn" disabled>Microphone: Off</button>
    <button id="speaker-btn" disabled>Speaker: Off</button>
    <div id="loader">â³ Processing...</div>

    <h3>Call Transcription:</h3>
    <div id="transcription">â€”</div>
  </div>

  <script type="module">
    import { evaluateS4Response } from './s4_guidelines.js';

    const startBtn = document.getElementById('start-btn');
    const sendBtn = document.getElementById('send-btn');
    const micBtn = document.getElementById('mic-btn');
    const speakerBtn = document.getElementById('speaker-btn');
    const loader = document.getElementById('loader');
    const transcriptionEl = document.getElementById('transcription');
    const autoSendCheckbox = document.getElementById('autoSendCheckbox');
    const timeoutSecondsInput = document.getElementById('timeoutSeconds');

    let recognition, finalTranscript = '', isRecognizing = false;
    let autoSendEnabled = true;
    let autoSendDelay = 60000;
    let autoSendTimer;
    let callStage = 'S1';
    let conversationHistory = [];
    let isSimulationActive = false;
    let evaluations = []; // Store evaluations for end-of-call summary

    function initRecognition() {
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR) {
        alert('Speech recognition not supported.');
        return null;
      }
      const rec = new SR();
      rec.lang = 'en-US';
      rec.interimResults = true;
      rec.continuous = true;

      rec.onstart = () => {
        isRecognizing = true;
        micBtn.disabled = false;
        micBtn.classList.add('active');
        micBtn.textContent = 'Microphone: On';
      };

      rec.onresult = e => {
        let interim = '';
        for (let i = e.resultIndex; i < e.results.length; i++) {
          const t = e.results[i][0].transcript;
          if (e.results[i].isFinal) {
            finalTranscript = t;
            if (t.toLowerCase().includes('send')) {
              clearTimeout(autoSendTimer);
              sendMessage(finalTranscript.replace(/send/i, '').trim());
              return;
            }
          } else {
            interim = t;
          }
        }
        transcriptionEl.innerHTML = transcriptionEl.innerHTML.replace(/Listening\.\.\.$/, '') + `Agent: ${finalTranscript + interim}<br>`;
        sendBtn.disabled = !finalTranscript.trim();

        if (autoSendEnabled && finalTranscript.trim()) {
          clearTimeout(autoSendTimer);
          autoSendTimer = setTimeout(() => {
            sendMessage(finalTranscript.trim());
          }, autoSendDelay);
        }
      };

      rec.onerror = e => {
        let errorMessage = e.error === 'network' ? 'Network error. Retrying in 3 seconds...' : `Speech error: ${e.error}`;
        transcriptionEl.innerHTML += `<b>Error:</b> ${errorMessage}<br>`;
        console.error('Speech error:', e.error);
        if (isRecognizing) {
          setTimeout(() => {
            if (isRecognizing) startRec();
          }, 3000);
        }
      };

      rec.onend = () => {
        if (!isRecognizing) {
          micBtn.classList.remove('active');
          micBtn.textContent = 'Microphone: Off';
          micBtn.disabled = true;
          sendBtn.disabled = true;
        }
      };

      return rec;
    }

    function startRec() {
      if (!recognition) recognition = initRecognition();
      finalTranscript = '';
      transcriptionEl.innerHTML += 'Listening...<br>';
      sendBtn.disabled = true;
      try {
        recognition.start();
      } catch (e) {
        transcriptionEl.innerHTML += '<b>Error:</b> Microphone access denied.<br>';
        stopRec();
      }
    }

    function stopRec() {
      if (recognition && isRecognizing) {
        recognition.stop();
        isRecognizing = false;
        clearTimeout(autoSendTimer);
      }
    }

    function sendMessage(text) {
      if (!text || !isSimulationActive) return;
      stopRec();
      sendBtn.disabled = true;
      loader.style.display = 'block';
      speakerBtn.disabled = false;
      speakerBtn.classList.add('active');
      speakerBtn.textContent = 'Speaker: On';

      transcriptionEl.innerHTML = transcriptionEl.innerHTML.replace(/Listening\.\.\.$/, '') + `<b>Agent:</b> ${text}<br>`;

      try {
        // Evaluate agent response, store for later
        const evaluation = evaluateS4Response(text, callStage, conversationHistory);
        evaluations.push({ text, comment: evaluation.comment, score: evaluation.score });
        conversationHistory.push({ role: 'agent', content: text });

        // Hardcoded customer response
        let reply = '';
        const lowerText = text.toLowerCase();
        if (conversationHistory.length === 1) {
          reply = 'Hello, this is Mark Smith.';
        } else if (lowerText.match(/how can i assist/i)) {
          reply = 'My bill is doubled and I didnâ€™t subscribe for any extra services. Would you check that for me?';
        } else if (lowerText.match(/verify your account/i)) {
          reply = 'Yes, sure.';
        } else if (lowerText.match(/provide.*account number|address|telephone/i)) {
          reply = 'Sure, my service address is 15 Northwest St, Ohio, 13557. My account number is 891700588128567. And my telephone number is 636-554-8121.';
        } else if (lowerText.match(/checking your bill/i)) {
          reply = 'Thank you.';
        } else if (lowerText.match(/reason for the increase/i)) {
          reply = 'Thank you so much. Thatâ€™s appreciated.';
        } else if (lowerText.match(/fixed.*200/i)) {
          reply = 'No, thatâ€™s all of it.';
        } else if (lowerText.match(/mobile.*discount/i)) {
          reply = 'Yeah, that looks like a good offer, so please schedule the callback for tomorrow at 2:00 PM Eastern Time.';
        } else if (lowerText.match(/schedule.*callback/i)) {
          reply = 'No, that is all of it.';
        } else {
          reply = 'Iâ€™m not sure how to respond to that. Can you assist with my bill issue?';
        }

        transcriptionEl.innerHTML += `<b>Customer:</b> ${reply}<br>`;
        conversationHistory.push({ role: 'customer', content: reply });
        transcriptionEl.scrollTop = transcriptionEl.scrollHeight;

        // Update call stage
        if (callStage === 'S1' && lowerText.match(/fixed|corrected/i)) {
          callStage = 'S2';
        } else if (callStage === 'S2' && lowerText.match(/offer|discount/i)) {
          callStage = 'S3';
        } else if (callStage === 'S3' && lowerText.match(/anything else|lovely day/i)) {
          callStage = 'S4';
        }

        speak(reply, () => {
          if (isSimulationActive) startRec();
        });
      } catch (e) {
        transcriptionEl.innerHTML += `<b>Error:</b> ${e.message}<br>`;
        console.error('Error:', e);
        speak('Error: Unable to respond.', () => {
          if (isSimulationActive) startRec();
        });
      } finally {
        loader.style.display = 'none';
        speakerBtn.classList.remove('active');
        speakerBtn.textContent = 'Speaker: Off';
        speakerBtn.disabled = true;
      }
    }

    function speak(text, callback) {
      if (!window.speechSynthesis) {
        console.log('Speech synthesis not supported.');
        if (callback) callback();
        return;
      }
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'en-US';
      utter.onend = () => {
        console.log('TTS finished');
        if (callback) callback();
      };
      window.speechSynthesis.speak(utter);
    }

    function resetSimulation() {
      stopRec();
      isSimulationActive = false;
      callStage = 'S1';
      conversationHistory = [];

      // Display evaluation summary
      if (evaluations.length > 0) {
        transcriptionEl.innerHTML += '<br><b>Evaluation Summary:</b><br>';
        evaluations.forEach((eval, index) => {
          transcriptionEl.innerHTML += `<b>Agent ${index + 1}:</b> ${eval.text}<br>${eval.comment}<br>`;
        });
      }

      evaluations = []; // Clear evaluations
      startBtn.textContent = 'ğŸ¤ Start Conversation';
      startBtn.classList.remove('active');
      sendBtn.disabled = true;
      micBtn.disabled = true;
      speakerBtn.disabled = true;
      transcriptionEl.scrollTop = transcriptionEl.scrollHeight;
    }

    startBtn.addEventListener('click', () => {
      if (isSimulationActive) {
        resetSimulation();
      } else {
        isSimulationActive = true;
        startBtn.textContent = 'ğŸ›‘ End Conversation';
        startBtn.classList.add('active');
        transcriptionEl.innerHTML = '';
        evaluations = [];
        startRec();
      }
    });

    sendBtn.addEventListener('click', () => {
      clearTimeout(autoSendTimer);
      sendMessage(finalTranscript);
    });

    autoSendCheckbox.addEventListener('change', (e) => {
      autoSendEnabled = e.target.checked;
      if (!autoSendEnabled) {
        clearTimeout(autoSendTimer);
      }
    });

    timeoutSecondsInput.addEventListener('input', (e) => {
      autoSendDelay = parseInt(e.target.value) * 1000 || 60000;
    });
  </script>
</body>
</html>
</xai>

---

### **Key Features**
1. **AI Call Flow**:
   - Hardcoded responses ensure the AI follows the exact call flow as Mark Smith (e.g., â€œHello, this is Mark Smithâ€ for the greeting).
   - Fallback response (â€œIâ€™m not sure how to respondâ€¦â€) for unexpected input.

2. **Single Transcription Box**:
   - `#transcription` div with `max-height: 400px` and `overflow-y: auto`.
   - During role-play: â€œAgent: [text]<br>Customer: [reply]<br>â€.
   - After â€œEnd Conversationâ€: Adds â€œ<br><b>Evaluation Summary:</b><br>â€ followed by evaluations for each agent response.
   - Auto-scrolls with `scrollTop = scrollHeight`.

3. **Comments**:
   - Suppressed during role-play, stored in `evaluations` array.
   - Displayed only after â€œEnd Conversationâ€ in a summary block, italicized, 1-2 lines, e.g., â€œ*S1: Greeting ME (3), Authenticate HE (4), Tone ME (3), Listening ME (3), Contact ME (3), Responsibility ME (4), Rapport ME (4), Score: 24*â€ or â€œ*S1: Greeting BE (0), Authenticate BE (0), Tone BE (0), Listening ME (3), Contact ME (3), Responsibility ME (4), Rapport BE (0), Score: 10. Say: â€˜Thank you for calling Comcast, Iâ€™m Leo. How may I help?â€™*â€.
   - Silent (not passed to `speak`).

4. **Customer Response**:
   - Uses TTS via `speak(reply, ...)`, follows call flow exactly.

5. **Start/End Button**:
   - Toggles â€œStart Conversationâ€ (green) and â€œEnd Conversationâ€ (red).
   - Ending triggers `resetSimulation`, displaying evaluations.

6. **Turn Management**:
   - `mic-btn` activates post-TTS via `startRec` in `speak`â€™s `onend`.
   - `speaker-btn` red during TTS, off after.

---

### **Example Interaction**
- **Agent**: â€œThank you for calling Comcast, this is Leo speaking, may I have your first and last name please?â€
  - **Transcription (during role-play)**:
    ```
    Agent: Thank you for calling Comcast, this is Leo speaking, may I have your first and last name please.
    Customer: Hello, this is Mark Smith.
    ```
  - **TTS**: â€œHello, this is Mark Smith.â€

- **Agent**: â€œHello Mark. How can I assist you today?â€
  - **Transcription**:
    ```
    Agent: Hello Mark. How can I assist you today?
    Customer: My bill is doubled and I didnâ€™t subscribe for any extra services. Would you check that for me?
    ```
  - **TTS**: â€œMy bill is doubledâ€¦â€

- **Click â€œEnd Conversationâ€**:
  - **Transcription**:
    ```
    Agent: Thank you for calling Comcast, this is Leo speaking, may I have your first and last name please.
    Customer: Hello, this is Mark Smith.
    Agent: Hello Mark. How can I assist you today?
    Customer: My bill is doubled and I didnâ€™t subscribe for any extra services. Would you check that for me?

    Evaluation Summary:
    Agent 1: Thank you for calling Comcast, this is Leo speaking, may I have your first and last name please.
    *S1: Greeting ME (3), Authenticate HE (4), Tone ME (3), Listening ME (3), Contact ME (3), Responsibility ME (4), Rapport ME (4), Score: 24*
    Agent 2: Hello Mark. How can I assist you today?
    *S1: Reflect BE (0), Tone ME (3), Listening ME (3), Contact ME (3), Responsibility ME (4), Rapport ME (4), Score: 17. Say: â€˜Thank you for calling Comcast, Iâ€™m Leo. How may I help?â€™*
    ```

---

### **Testing Plan**
Host locally (`npx http-server`) with `s4_guidelines.js` in the same directory. Test in Chrome at 06:09 AM EEST, May 28, 2025.

1. **Setup**:
   - Save both files.
   - Open `index.html`, grant mic access.

2. **Test Call Flow**:
   - **Step 1**: Click â€œStart Conversation.â€
     - Verify: `start-btn` â†’ â€œEnd Conversationâ€ (red), `mic-btn` red, `#transcription` shows â€œListeningâ€¦â€.
   - **Step 2**: Say: â€œThank you for calling Comcast, this is Leo speaking, may I have your first and last name please.â€
     - Verify: `#transcription` shows:
       ```
       Agent: Thank you for calling Comcast, this is Leo speaking, may I have your first and last name please.
       Customer: Hello, this is Mark Smith.
       ```
     - TTS: â€œHello, this is Mark Smith.â€
     - Confirm: No comments displayed.
   - **Step 3**: Say: â€œHello Mark. How can I assist you today?â€
     - Verify: `#transcription` adds:
       ```
       Agent: Hello Mark. How can I assist you today?
       Customer: My bill is doubled and I didnâ€™t subscribe for any extra services. Would you check that for me?
       ```
     - TTS: â€œMy bill is doubledâ€¦â€
   - **Step 4**: Continue through the call flow (e.g., â€œIâ€™m sorry for this inconvenienceâ€¦â€ â†’ â€œYes, sure.â€).
   - **Step 5**: Test incorrect input (e.g., â€œRandom textâ€).
     - Verify: Customer says â€œIâ€™m not sure how to respondâ€¦â€, no comments.
   - **Step 6**: Click â€œEnd Conversation.â€
     - Verify: `#transcription` appends evaluation summary with comments for all agent responses, state resets, `start-btn` â†’ â€œStart Conversation.â€

3. **Test Comments**:
   - Confirm comments appear only after â€œEnd Conversationâ€, are italicized, silent, 1-2 lines, with BE recommendations.
   - Verify summary lists each agent response and its evaluation.

4. **Test Turn Management**:
   - Confirm `mic-btn` reactivates post-TTS.
   - Check `speaker-btn` red during TTS, off after.

5. **Test Auto-Send**:
   - Wait 60 seconds or say â€œsend,â€ verify message sends.

6. **Test Errors**:
   - Disconnect Wi-Fi, check retry in `#transcription`.
   - Verify errors logged.

---

### **Troubleshooting**
- **AI Wrong Response**:
  - Check `sendMessage` hardcoded responses.
  - Share `#transcription` output.
- **Comments During Role-Play**:
  - Confirm `evaluations` only displayed in `resetSimulation`.
  - Share `#transcription` content.
- **Comments in TTS**:
  - Verify only `reply` passed to `speak`.
  - Share spoken text.
- **No Summary**:
  - Check `evaluations` array in `resetSimulation`.
  - Share console logs.

Please test and confirm:
- AI follows the exact call flow (e.g., â€œHello, this is Mark Smithâ€).
- `#transcription` shows only dialogue during role-play.
- Evaluation summary appears only after â€œEnd Conversationâ€, with silent comments.
- Customer responses use TTS correctly.

Share console logs or issues (e.g., â€œComments appeared during role-playâ€). Iâ€™ll fix any problems immediately!
